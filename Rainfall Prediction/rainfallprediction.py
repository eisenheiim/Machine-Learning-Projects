# -*- coding: utf-8 -*-
"""RainfallPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gtaGtkLYEMTb5BkdcnQcqQPC6Vzt5fP5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import RandomOverSampler

import warnings
warnings.filterwarnings('ignore')

data=pd.read_csv("/content/Rainfall.csv")

"""Data Preprocessing"""

data.shape

data.head()

data.info()

data.isnull().sum()

data.columns
#there is unnecessary space in the name of winddirection

data.rename(str.strip,
          axis=1,
          inplace=True)

data.columns

#null value imputation
for column in data.columns:
  if data[column].isnull().sum()>0:
    avg=data[column].mean()
    data[column]=data[column].fillna(avg)

"""Data Analysis"""

yes_number=(data.rainfall=="yes").sum()
no_number=(data.rainfall=="no").sum()
print(yes_number,no_number)

fig=plt.figure(figsize=(4,4))
categ =data['rainfall'].unique().tolist()
number=[yes_number,no_number]
ax=fig.add_axes([0,0,1,1])
ax.bar(categ,number)

fig.show

fig=plt.figure(figsize=(4,4))
ax=fig.add_axes([0,0,1,1])
ax.scatter(categ,number)
fig.show

sb.countplot(x="rainfall",data=data)

rainfall_data=data.rainfall.value_counts()
rainfall_data

numbers=rainfall_data.values
numbers

categ=rainfall_data.index
categ

plt.pie(numbers,labels=categ,autopct='%1.1f%%')
plt.show()

"""You can draw conclusions looking at that mean data"""

data.groupby("rainfall").mean()

"""Observations:

maxtemp is relatively lower on days of rainfall.
dewpoint value is higher on days of rainfall.
humidity is high on the days when rainfall is expected.
Obviously, clouds must be there for rainfall.
sunshine is also less on days of rainfall.
windspeed is higher on days of rainfall.

Selecting columns involving numeric values
"""

numeric_features=list(data.select_dtypes(include=np.number).columns)
numeric_features

numeric_features.remove("day")

plt.subplots(figsize=(15,8))

for i, col in enumerate(numeric_features):
  plt.subplot(3,4, i + 1)  #3 satır 4 sütunluk bir grid
  sb.distplot(data[col])
plt.tight_layout()#grafiklerin üst üste binmesini önler
plt.show()

"""Lets check outliers"""

plt.subplots(figsize=(15,8))

for i, col in enumerate(numeric_features):
  plt.subplot(3,4, i + 1)
  sb.boxplot(data[col])
plt.tight_layout()
plt.show()

"""there are outliers but we dont have much data , we cant remove it

Lets check corroleation
"""



data.rainfall=np.where(data.rainfall=="yes",1,0)
data.head()

corrolated=data.corr(numeric_only=1)
sb.heatmap(corrolated>0.8,annot=True,cmap="Blues")

#we can see that maxtemp and mintep are highly corroleated with temp. there are some other corroleated ones too but they
#provide distint information about data.

#so we the min-max temp.
data.drop(["mintemp","maxtemp"],axis=1,inplace=True)

corrolated=data.corr(numeric_only=1)
sb.heatmap(corrolated>0.8,annot=True,cmap="Blues")

"""Train-Test Split"""

x=data.drop(["day", "rainfall"],axis=1)
y=data.rainfall

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=2,stratify=y)

#our data is highly imbalanced so we have to balanca it
sampler=RandomOverSampler(sampling_strategy="minority",random_state=22)

x_train,y_train=sampler.fit_resample(x_train,y_train)

#features are at different scale,so we have to standarize it
scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
x_test=scaler.transform(x_test)

"""Model Training"""

models=[LogisticRegression(),XGBClassifier(),SVC(kernel='rbf', probability=True)]

from sklearn.metrics import accuracy_score

models = [LogisticRegression(), XGBClassifier(), SVC(kernel='rbf', probability=True)]

for i in range(3):
  models[i].fit(x_train,y_train)

  print(f'{models[i]} : ')

  train_preds = models[i].predict_proba(x_train)
  print('Training Accuracy : ', metrics.roc_auc_score(y_train, train_preds[:,1]))

  val_preds = models[i].predict_proba(x_test)
  print('Validation Accuracy : ', metrics.roc_auc_score(y_test, val_preds[:,1]))
  print()

"""We can see that there is overfitting at xgb classifier. Even though we did sampling, accuracy score is misleading when there is imbalanced data set. So we have to check other metrics.

Model Evaluation
"""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn import metrics

ConfusionMatrixDisplay.from_estimator(models[2], x_train, y_train)
plt.show()

print(metrics.classification_report(y_test,
                                    models[2].predict(x_test)))

print(metrics.classification_report(y_test,
                                    models[0].predict(x_test)))

